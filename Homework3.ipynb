{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Основное задание:__\n",
    "Даны выборки для обучения и для тестирования. Задание заключается в том, чтобы попробовать разные способы валидации, проанализировать плюсы / минусы каждой и сделать выводы о том, какой способ валидации наиболее устойчивый в данной задаче. Метрика качества для оценки прогнозов - ROC-AUC, название целевой переменной - IsFraud. Рекомендуется использовать модели градиетного бустинга, реализация любая / гипепараметры любые. Внимание! выборка assignment_2_test.csv - наш аналог лидерборда. Будем моделировать ситуацию отправки решения на лидерборд и сравнить значение метрики на лидерборде и на локальной валидации. Для других целей использовать выборку запрещено!.\n",
    "​\n",
    "Терминалогия, используемая в задании:\n",
    "* обучающая выборка - выборка, которая передается в метод fit / train;\n",
    "* валидационная выборка - выборка, которая получается при Hold-Out на 2 выборки (train, valid);\n",
    "* тестовая выборка - выборка, которая получается при Hold-Out на 3 выборки (train, valid, test);\n",
    "* ЛБ - лидерборд, выборка assignment_2_test.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from scipy.stats import probplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape = 180000 rows, 394 cols\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "\n",
       "   card2  card3       card4  card5  ... V330  V331  V332  V333  V334 V335  \\\n",
       "0    NaN  150.0    discover  142.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "\n",
       "  V336  V337  V338  V339  \n",
       "0  NaN   NaN   NaN   NaN  \n",
       "1  NaN   NaN   NaN   NaN  \n",
       "\n",
       "[2 rows x 394 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\n",
    "    \"data/assignment_2_train.csv\"\n",
    ")\n",
    "print(\"data.shape = {} rows, {} cols\".format(*train_data.shape))\n",
    "train_data.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape = 100001 rows, 394 cols\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3287000</td>\n",
       "      <td>1</td>\n",
       "      <td>7415038</td>\n",
       "      <td>226.0</td>\n",
       "      <td>W</td>\n",
       "      <td>12473</td>\n",
       "      <td>555.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3287001</td>\n",
       "      <td>0</td>\n",
       "      <td>7415054</td>\n",
       "      <td>3072.0</td>\n",
       "      <td>W</td>\n",
       "      <td>15651</td>\n",
       "      <td>417.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        3287000        1        7415038           226.0         W  12473   \n",
       "1        3287001        0        7415054          3072.0         W  15651   \n",
       "\n",
       "   card2  card3 card4  card5  ... V330  V331  V332  V333  V334 V335 V336  \\\n",
       "0  555.0  150.0  visa  226.0  ...  NaN   NaN   NaN   NaN   NaN  NaN  NaN   \n",
       "1  417.0  150.0  visa  226.0  ...  NaN   NaN   NaN   NaN   NaN  NaN  NaN   \n",
       "\n",
       "   V337  V338  V339  \n",
       "0   NaN   NaN   NaN  \n",
       "1   NaN   NaN   NaN  \n",
       "\n",
       "[2 rows x 394 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\n",
    "    \"data/assignment_2_test.csv\"\n",
    ")\n",
    "print(\"data.shape = {} rows, {} cols\".format(*test_data.shape))\n",
    "test_data.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = train_data.select_dtypes(include=[np.number])\n",
    "lb_numerical_features = test_data.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = numerical_features['isFraud']\n",
    "lb_target = lb_numerical_features['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = numerical_features.drop(['TransactionID', 'isFraud'], axis=1)\n",
    "lb_numerical_features = lb_numerical_features.drop(['TransactionID', 'isFraud'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1:__ сделать Hold-Out валидацию с разбиением, размер которого будет адекватным, по вашему мнению; разбиение проводить по id-транзакции (TransactionID), обучать модель градиетного бустинга любой реализации с подбором числа деревьев по early_stopping критерию до достижения сходимости. Оценить качество модели на валидационной выборке, оценить расхождение по сравнению с качеством на обучающей выборке и валидационной выборке. Оценить качество на ЛБ, сравнить с качеством на обучении и валидации. Сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = train_test_split(numerical_features, train_size=0.75, random_state=42)\n",
    "y_train, y_valid = train_test_split(target, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((135000, 378), (45000, 378))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"reg_lambda\": 100,\n",
    "    \"max_depth\": 4,\n",
    "    \"gamma\": 10,\n",
    "    \"nthread\": 6,\n",
    "    \"seed\": 27\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "xgb_valid = xgb.DMatrix(data=X_valid, label=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:42:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.65337\tvalid-auc:0.63889\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 50 rounds.\n",
      "[50]\ttrain-auc:0.88480\tvalid-auc:0.87192\n",
      "[100]\ttrain-auc:0.90036\tvalid-auc:0.88795\n",
      "[150]\ttrain-auc:0.90673\tvalid-auc:0.89292\n",
      "Stopping. Best iteration:\n",
      "[133]\ttrain-auc:0.90669\tvalid-auc:0.89292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=xgb_train,\n",
    "    num_boost_round=1000,\n",
    "    early_stopping_rounds=50,\n",
    "    evals=[(xgb_train, \"train\"), (xgb_valid, \"valid\")],\n",
    "    verbose_eval=50,\n",
    "    maximize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model1.predict(xgb_train)\n",
    "y_valid_pred = model1.predict(xgb_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9067251551175555, 0.892919719610207)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, y_train_pred), roc_auc_score(y_valid, y_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8580454525237254"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_lb = xgb.DMatrix(data=lb_numerical_features, label=lb_target)\n",
    "y_lb_pred = model1.predict(xgb_lb)\n",
    "roc_auc_score(lb_target, y_lb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разница метрики качества на тренировочной и валидационной выборке очень небольшое (1.5%). По такой разнице можно было бы говорить об отсутствии переобучения. Но при переход на ЛБ качество сильно падает, что говорит о том, что модель неустойчива (и мы видели в прошлом д/з, что распределение сумм транзакций на тренировочной и тестовой выборках разное, что в том числе приводит к ухудшению метрики на ЛБ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2:__ сделать Hold-Out валидацию с разбиением на 3 выборки, разбиение проводить по id-транзакции (TransactionID), размер каждой выборки подобрать самостоятельно. Повторить процедуру из п.1. для каждой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(numerical_features, train_size=0.8, random_state=42)\n",
    "X_train, X_valid = train_test_split(X_train, train_size=0.75, random_state=42)\n",
    "y_train, y_test = train_test_split(target, train_size=0.8, random_state=42)\n",
    "y_train, y_valid = train_test_split(y_train, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "xgb_valid = xgb.DMatrix(data=X_valid, label=y_valid)\n",
    "xgb_test = xgb.DMatrix(data=X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:19:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.65507\tvalid-auc:0.64410\ttest-auc:0.63977\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "[10]\ttrain-auc:0.75290\tvalid-auc:0.73784\ttest-auc:0.73806\n",
      "[20]\ttrain-auc:0.82171\tvalid-auc:0.82093\ttest-auc:0.81478\n",
      "[30]\ttrain-auc:0.85931\tvalid-auc:0.85505\ttest-auc:0.84872\n",
      "[40]\ttrain-auc:0.86806\tvalid-auc:0.86384\ttest-auc:0.86224\n",
      "[50]\ttrain-auc:0.88223\tvalid-auc:0.87520\ttest-auc:0.87255\n",
      "[60]\ttrain-auc:0.88862\tvalid-auc:0.87939\ttest-auc:0.87758\n",
      "[70]\ttrain-auc:0.89207\tvalid-auc:0.88193\ttest-auc:0.88076\n",
      "[80]\ttrain-auc:0.89471\tvalid-auc:0.88412\ttest-auc:0.88329\n",
      "[90]\ttrain-auc:0.89642\tvalid-auc:0.88517\ttest-auc:0.88473\n",
      "[100]\ttrain-auc:0.89871\tvalid-auc:0.88675\ttest-auc:0.88614\n",
      "[110]\ttrain-auc:0.90088\tvalid-auc:0.88828\ttest-auc:0.88798\n",
      "[120]\ttrain-auc:0.90333\tvalid-auc:0.89007\ttest-auc:0.89022\n",
      "[130]\ttrain-auc:0.90472\tvalid-auc:0.89140\ttest-auc:0.89127\n",
      "[140]\ttrain-auc:0.90472\tvalid-auc:0.89140\ttest-auc:0.89127\n",
      "[150]\ttrain-auc:0.90472\tvalid-auc:0.89140\ttest-auc:0.89127\n",
      "[160]\ttrain-auc:0.90472\tvalid-auc:0.89140\ttest-auc:0.89127\n",
      "[170]\ttrain-auc:0.90472\tvalid-auc:0.89140\ttest-auc:0.89127\n",
      "Stopping. Best iteration:\n",
      "[129]\ttrain-auc:0.90472\tvalid-auc:0.89140\ttest-auc:0.89127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=xgb_train,\n",
    "    num_boost_round=1000,\n",
    "    early_stopping_rounds=50,\n",
    "    evals=[(xgb_train, \"train\"), (xgb_valid, \"valid\"), (xgb_test, \"test\")],\n",
    "    verbose_eval=10,\n",
    "    maximize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9047161422370005, 0.8913999612625666, 0.8912672273354262)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = model.predict(xgb_train)\n",
    "y_valid_pred = model.predict(xgb_valid)\n",
    "y_test_pred = model.predict(xgb_test)\n",
    "roc_auc_score(y_train, y_train_pred), roc_auc_score(y_valid, y_valid_pred), roc_auc_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8578127448703862"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_lb = xgb.DMatrix(data=lb_numerical_features, label=lb_target)\n",
    "y_lb_pred = model.predict(xgb_lb)\n",
    "roc_auc_score(lb_target, y_lb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество на тестовой выборке ухудшается по сравнению с валидационной, но разница с качеством на тренировочной выборке все еще небольшая. Качество на ЛБ стало хуже по сравнению с Задачей 1 (возможно из-за того, что модель обучалась на меньшем количестве данных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 3:__ построить доверительный интервал на данных из п.2 на основе бутстреп выборок, оценить качество модели на ЛБ относительно полученного доверительного интервала. Сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bootstrap_samples(data: np.array, n_samples: int = 1000) -> np.array:\n",
    "    \"\"\"\n",
    "    Создание бутстреп-выборок.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: np.array\n",
    "        Исходная выборка, которая будет использоваться для\n",
    "        создания бутстреп выборок.\n",
    "\n",
    "    n_samples: int, optional, default = 1000\n",
    "        Количество создаваемых бутстреп выборок.\n",
    "        Опциональный параметр, по умолчанию, равен 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bootstrap_idx: np.array\n",
    "        Матрица индексов, для создания бутстреп выборок.\n",
    "\n",
    "    \"\"\"\n",
    "    bootstrap_idx = np.random.randint(\n",
    "        low=0, high=len(data), size=(n_samples, len(data))\n",
    "    )\n",
    "    return bootstrap_idx\n",
    "\n",
    "\n",
    "def create_bootstrap_metrics(y_true: np.array,\n",
    "                             y_pred: np.array,\n",
    "                             metric: callable,\n",
    "                             n_samlpes: int = 1000) -> List[float]:\n",
    "    \"\"\"\n",
    "    Вычисление бутстреп оценок.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: np.array\n",
    "        Вектор целевой переменной.\n",
    "\n",
    "    y_pred: np.array\n",
    "        Вектор прогнозов.\n",
    "\n",
    "    metric: callable\n",
    "        Функция для вычисления метрики.\n",
    "        Функция должна принимать 2 аргумента: y_true, y_pred.\n",
    "\n",
    "    n_samples: int, optional, default = 1000\n",
    "        Количество создаваемых бутстреп выборок.\n",
    "        Опциональный параметр, по умолчанию, равен 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bootstrap_metrics: List[float]\n",
    "        Список со значениями метрики качества на каждой бустреп выборке.\n",
    "\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    if isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "\n",
    "    bootstrap_idx = create_bootstrap_samples(y_true)\n",
    "    for idx in bootstrap_idx:\n",
    "        y_true_bootstrap = y_true[idx]\n",
    "        y_pred_bootstrap = y_pred[idx]\n",
    "\n",
    "        score = metric(y_true_bootstrap, y_pred_bootstrap)\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def calculate_confidence_interval(scores: list, conf_interval: float = 0.95) -> Tuple[float]:\n",
    "    \"\"\"\n",
    "    Вычисление доверительного интервала.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scores: List[float / int]\n",
    "        Список с оценками изучаемой величины.\n",
    "\n",
    "    conf_interval: float, optional, default = 0.95\n",
    "        Уровень доверия для построения интервала.\n",
    "        Опциональный параметр, по умолчанию, равен 0.95.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    conf_interval: Tuple[float]\n",
    "        Кортеж с границами доверительного интервала.\n",
    "\n",
    "    \"\"\"\n",
    "    left_bound = np.percentile(\n",
    "        scores, ((1 - conf_interval) / 2) * 100\n",
    "    )\n",
    "    right_bound = np.percentile(\n",
    "        scores, (conf_interval + ((1 - conf_interval) / 2)) * 100\n",
    "    )\n",
    "\n",
    "    return left_bound, right_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8787561892268496, 0.9036474502323957)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "scores = create_bootstrap_metrics(y_test, model.predict(xgb_test), roc_auc_score)\n",
    "\n",
    "calculate_confidence_interval(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение метрики качества на ЛБ не попадает в доверительный интервал, значит модель неустойчива (валидация плохая)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4:__ выполнить Adversarial Validation, подобрать объекты из обучающей выборки, которые сильно похожи на объекты из assignment_2_test.csv, и использовать их в качестве валидационного набора. Оценить качество модели на ЛБ, сделать выводы о полученных результатах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если столбец TransactionDT оставлять в числе признаков, то модель разделяет выборки абсолютно точно.\n",
    "Поэтом рассмотрим два варианта: \n",
    "\n",
    "1) удалить только столбец TransactionDT\n",
    "\n",
    "2) оставить только столбец TransactionAmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_adv = pd.concat([\n",
    "    numerical_features, lb_numerical_features], axis=0\n",
    ")\n",
    "y_adv = np.hstack((np.zeros(numerical_features.shape[0]), np.ones(lb_numerical_features.shape[0])))\n",
    "assert X_adv.shape[0] == y_adv.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_adv = X_adv.drop('TransactionDT', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=4, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_adv = xgb.XGBClassifier(n_estimators=4)\n",
    "model_adv.fit(X_adv, y_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85706887\n"
     ]
    }
   ],
   "source": [
    "y_pred_adv = model_adv.predict_proba(X_adv)\n",
    "score = roc_auc_score(y_adv, y_pred_adv[:, 1])\n",
    "print(round(score, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53209764, 0.46790236],\n",
       "       [0.6158279 , 0.38417208],\n",
       "       [0.7646603 , 0.23533969],\n",
       "       ...,\n",
       "       [0.14235139, 0.8576486 ],\n",
       "       [0.7742394 , 0.22576055],\n",
       "       [0.8066354 , 0.19336465]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_adv.predict_proba(numerical_features.drop('TransactionDT', axis=1))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.1]        0\n",
       "(0.1, 0.2]    27125\n",
       "(0.2, 0.3]    93268\n",
       "(0.3, 0.4]    20554\n",
       "(0.4, 0.5]    38537\n",
       "(0.5, 0.6]      135\n",
       "(0.6, 0.7]       45\n",
       "(0.7, 0.8]       76\n",
       "(0.8, 0.9]      260\n",
       "(0.9, 1.0]        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(\n",
    "    y_pred[:, 1], bins=np.arange(0, 1.01, 0.1)\n",
    ").value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13777602, 0.862224  ],\n",
       "       [0.6158279 , 0.38417208],\n",
       "       [0.74375236, 0.25624767],\n",
       "       ...,\n",
       "       [0.57889616, 0.42110386],\n",
       "       [0.73012793, 0.2698721 ],\n",
       "       [0.14235139, 0.8576486 ]], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lb = model_adv.predict_proba(lb_numerical_features.drop('TransactionDT', axis=1))\n",
    "y_pred_lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.1]        0\n",
       "(0.1, 0.2]     1599\n",
       "(0.2, 0.3]    13636\n",
       "(0.3, 0.4]     7867\n",
       "(0.4, 0.5]    31538\n",
       "(0.5, 0.6]      842\n",
       "(0.6, 0.7]     1181\n",
       "(0.7, 0.8]     1372\n",
       "(0.8, 0.9]    41957\n",
       "(0.9, 1.0]        9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(\n",
    "    y_pred_lb[:, 1], bins=np.arange(0, 1.01, 0.1)\n",
    ").value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = numerical_features[y_pred[:, 1] < 0.4]\n",
    "y_train = target[y_pred[:, 1] < 0.4]\n",
    "\n",
    "X_valid = numerical_features[y_pred[:, 1] >= 0.4]\n",
    "y_valid = target[y_pred[:, 1] >= 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "xgb_valid = xgb.DMatrix(data=X_valid, label=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:37:26] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.62234\tvalid-auc:0.63181\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 50 rounds.\n",
      "[50]\ttrain-auc:0.88485\tvalid-auc:0.87499\n",
      "[100]\ttrain-auc:0.89993\tvalid-auc:0.88227\n",
      "[150]\ttrain-auc:0.90490\tvalid-auc:0.88571\n",
      "Stopping. Best iteration:\n",
      "[130]\ttrain-auc:0.90490\tvalid-auc:0.88576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model4_1 = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=xgb_train,\n",
    "    num_boost_round=1000,\n",
    "    early_stopping_rounds=50,\n",
    "    evals=[(xgb_train, \"train\"), (xgb_valid, \"valid\")],\n",
    "    verbose_eval=50,\n",
    "    maximize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model4_1.predict(xgb_train)\n",
    "y_valid_pred = model4_1.predict(xgb_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9049049801930201, 0.8857141353213357)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, y_train_pred), roc_auc_score(y_valid, y_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_adv = pd.concat([\n",
    "    numerical_features, lb_numerical_features], axis=0\n",
    ")\n",
    "y_adv = np.hstack((np.zeros(numerical_features.shape[0]), np.ones(lb_numerical_features.shape[0])))\n",
    "assert X_adv.shape[0] == y_adv.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_adv = X_adv[['TransactionAmt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=4, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_adv = xgb.XGBClassifier(n_estimators=4)\n",
    "model_adv.fit(X_adv, y_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6331042\n"
     ]
    }
   ],
   "source": [
    "y_pred_adv = model_adv.predict_proba(X_adv)\n",
    "score = roc_auc_score(y_adv, y_pred_adv[:, 1])\n",
    "print(round(score, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57853585, 0.42146415],\n",
       "       [0.5999787 , 0.40002128],\n",
       "       [0.54255724, 0.4574428 ],\n",
       "       ...,\n",
       "       [0.5859054 , 0.41409463],\n",
       "       [0.54255724, 0.4574428 ],\n",
       "       [0.56292   , 0.43708   ]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_adv.predict_proba(numerical_features[['TransactionAmt']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.1]         0\n",
       "(0.1, 0.2]        86\n",
       "(0.2, 0.3]     43720\n",
       "(0.3, 0.4]     23787\n",
       "(0.4, 0.5]    112379\n",
       "(0.5, 0.6]        26\n",
       "(0.6, 0.7]         0\n",
       "(0.7, 0.8]         2\n",
       "(0.8, 0.9]         0\n",
       "(0.9, 1.0]         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(\n",
    "    y_pred[:, 1], bins=np.arange(0, 1.01, 0.1)\n",
    ").value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56292   , 0.43708   ],\n",
       "       [0.56827813, 0.43172187],\n",
       "       [0.5640924 , 0.43590763],\n",
       "       ...,\n",
       "       [0.6112087 , 0.38879132],\n",
       "       [0.5859054 , 0.41409463],\n",
       "       [0.5640924 , 0.43590763]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lb = model_adv.predict_proba(lb_numerical_features[['TransactionAmt']])\n",
    "y_pred_lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.1]        0\n",
       "(0.1, 0.2]        2\n",
       "(0.2, 0.3]     5936\n",
       "(0.3, 0.4]    10806\n",
       "(0.4, 0.5]    83133\n",
       "(0.5, 0.6]      103\n",
       "(0.6, 0.7]        0\n",
       "(0.7, 0.8]       21\n",
       "(0.8, 0.9]        0\n",
       "(0.9, 1.0]        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(\n",
    "    y_pred_lb[:, 1], bins=np.arange(0, 1.01, 0.1)\n",
    ").value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = numerical_features[y_pred[:, 1] < 0.4]\n",
    "y_train = target[y_pred[:, 1] < 0.4]\n",
    "\n",
    "X_valid = numerical_features[y_pred[:, 1] >= 0.4]\n",
    "y_valid = target[y_pred[:, 1] >= 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "xgb_valid = xgb.DMatrix(data=X_valid, label=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:25:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.69303\tvalid-auc:0.59641\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 50 rounds.\n",
      "[50]\ttrain-auc:0.92400\tvalid-auc:0.82114\n",
      "[100]\ttrain-auc:0.93697\tvalid-auc:0.84084\n",
      "[150]\ttrain-auc:0.93747\tvalid-auc:0.84169\n",
      "Stopping. Best iteration:\n",
      "[103]\ttrain-auc:0.93733\tvalid-auc:0.84191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model4_2 = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=xgb_train,\n",
    "    num_boost_round=1000,\n",
    "    early_stopping_rounds=50,\n",
    "    evals=[(xgb_train, \"train\"), (xgb_valid, \"valid\")],\n",
    "    verbose_eval=50,\n",
    "    maximize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model4_2.predict(xgb_train)\n",
    "y_valid_pred = model4_2.predict(xgb_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9374683703264246, 0.8416872576546874)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, y_train_pred), roc_auc_score(y_valid, y_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первом случае мы видим падение метрики качества на 1.5 пункта, во втором на 9. Это говорит о том, что модель неустройчива и при переходе к ЛБ качество предсказания также может стать ниже на 9 пунктов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно еще model1 из задания 1 применить к данным, \"похожим\" на ЛБ, но при этом значение метрики меняется не так существенно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.892919719610207"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_pred = model1.predict(xgb_valid)\n",
    "roc_auc_score(y_valid, y_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 5:__ сделать KFold / StratifiedKFold валидацию (на ваше усмотрение), оценить получаемые качество и разброс по метрике качества. Сделать выводы об устойчивости кросс-валидации, сходимости оценки на кросс-валидации и отложенном наборе данных; Оценить качество на ЛБ, сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cross_validation(X: pd.DataFrame,\n",
    "                          y: pd.Series,\n",
    "                          cv_strategy):\n",
    "  \n",
    "    models, fold_train_scores, fold_valid_scores = [], [], []\n",
    "    oof_predictions = np.zeros(X.shape[0])\n",
    "\n",
    "    for fold_number, (train_idx, valid_idx) in enumerate(cv_strategy.split(X, y)):\n",
    "        x_train, x_valid = X.loc[train_idx], X.loc[valid_idx]\n",
    "        y_train, y_valid = y.loc[train_idx], y.loc[valid_idx]\n",
    "\n",
    "        \n",
    "        xgb_train = xgb.DMatrix(data=x_train, label=y_train)\n",
    "        xgb_valid = xgb.DMatrix(data=x_valid, label=y_valid)\n",
    "        model = xgb.train(\n",
    "                        params=params,\n",
    "                        dtrain=xgb_train,\n",
    "                        num_boost_round=300,\n",
    "                        early_stopping_rounds=50,\n",
    "                        evals=[(xgb_train, \"train\"), (xgb_valid, \"valid\")],\n",
    "                        verbose_eval=0,\n",
    "                        maximize=True,\n",
    "                    )\n",
    "        y_train_pred = model.predict(xgb_train)\n",
    "        y_valid_pred = model.predict(xgb_valid)\n",
    "\n",
    "        fold_train_scores.append(roc_auc_score(y_train, y_train_pred))\n",
    "        fold_valid_scores.append(roc_auc_score(y_valid, y_valid_pred))\n",
    "        oof_predictions[valid_idx] = y_valid_pred\n",
    "\n",
    "        msg = (\n",
    "            f\"Fold: {fold_number+1}, train-observations = {len(train_idx)}, \"\n",
    "            f\"valid-observations = {len(valid_idx)}\\n\"\n",
    "            f\"train-score = {round(fold_train_scores[fold_number], 4)}, \"\n",
    "            f\"valid-score = {round(fold_valid_scores[fold_number], 4)}\" \n",
    "        )\n",
    "        print(msg)\n",
    "        print(\"=\"*69)\n",
    "        models.append(model)\n",
    "\n",
    "    oof_score = roc_auc_score(y, oof_predictions)\n",
    "    print(f\"CV-results train: {round(np.mean(fold_train_scores), 4)} +/- {round(np.std(fold_train_scores), 3)}\")\n",
    "    print(f\"CV-results valid: {round(np.mean(fold_valid_scores), 4)} +/- {round(np.std(fold_valid_scores), 3)}\")\n",
    "    print(f\"OOF-score = {round(oof_score, 4)}\")\n",
    "\n",
    "    return models, oof_score, fold_train_scores, fold_valid_scores, oof_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:37:35] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Fold: 1, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.9132, valid-score = 0.8706\n",
      "=====================================================================\n",
      "[03:39:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Fold: 2, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.9114, valid-score = 0.8918\n",
      "=====================================================================\n",
      "[03:41:28] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Fold: 3, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.907, valid-score = 0.8989\n",
      "=====================================================================\n",
      "[03:43:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Fold: 4, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.912, valid-score = 0.8902\n",
      "=====================================================================\n",
      "[03:45:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Fold: 5, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.9085, valid-score = 0.8837\n",
      "=====================================================================\n",
      "CV-results train: 0.9104 +/- 0.002\n",
      "CV-results valid: 0.887 +/- 0.01\n",
      "OOF-score = 0.8868\n"
     ]
    }
   ],
   "source": [
    "cv_strategy = KFold(n_splits=5, random_state=42)\n",
    "\n",
    "models, oof_score, fold_train_scores, fold_valid_scores, oof_predictions = make_cross_validation(\n",
    "    numerical_features, target, cv_strategy=cv_strategy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение метрики при кросс-валидации на валидационных данных ниже, чем при OH разбиении и соответственно ближе к метрики на ЛБ. OOF-score по все выборке крактически совпадает со средним значением метрики на валидационных выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_lb = xgb.DMatrix(data=lb_numerical_features, label=lb_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lb_preds = []\n",
    "for model in models:\n",
    "    y_lb_pred = model.predict(xgb_lb)\n",
    "    y_lb_preds.append(y_lb_pred)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = list(zip(*y_lb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lb_pred_avg = []\n",
    "for pred in preds:\n",
    "    y_lb_pred_avg.append(np.mean(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.861109900963724"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(lb_target, y_lb_pred_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель, получившаяся усреднением моделей, полученных при кросс-валидации получилась более устройчивая. Значение метрики на ЛБ такой усредненной модели ближе к значениям на валидационных метриках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
